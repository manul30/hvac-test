import cv2
import tempfile
import uuid
from ultralytics import YOLO

video_registry = {}


def save_temp_video(file_bytes: bytes) -> str:
    """
    Save uploaded video to a temporary file and register it with a UUID.
    """
    uid = str(uuid.uuid4())
    temp_file = tempfile.NamedTemporaryFile(
        delete=False, suffix=".mp4", prefix=f"{uid}_"
    )
    temp_file.write(file_bytes)
    temp_file.close()
    video_registry[uid] = temp_file.name
    return uid


def get_video_path(uid: str) -> str | None:
    """
    Return the path of the video file registered by UUID.
    """
    return video_registry.get(uid)


def generate_stream(video_path: str, model: YOLO):
    """
    Generator that yields annotated frames from the video as MJPEG stream.
    """
    cap = cv2.VideoCapture(video_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        results = model.predict(frame)

        # Suponiendo que results contiene las cajas y clases detectadas
        annotated = frame.copy()
        for box in results:  # Ajusta seg√∫n el formato de salida de postprocess
            x1, y1, x2, y2, conf, cls = box  # ejemplo: [x1, y1, x2, y2, conf, class]
            cv2.rectangle(annotated, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,0), 2)
            label = cls + ": "+ str(conf)
            cv2.putText(annotated, label, (int(x1), int(y1)-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)

        ret, buffer = cv2.imencode(".jpg", annotated)
        if not ret:
            continue

        yield (
            b"--frame\r\n"
            b"Content-Type: image/jpeg\r\n\r\n" + buffer.tobytes() + b"\r\n"
        )
    cap.release()
